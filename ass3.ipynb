{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import random \n",
    "\n",
    "import  matplotlib.image as mping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "import tensorflow\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingImagePath=\"/content/drive/MyDrive/Image /train\"\n",
    "TestImagePath=\"/content/drive/MyDrive/Image /test\"\n",
    "ValidationImagePath=\"/content/drive/MyDrive/Image /valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(    \n",
    "    rescale = 1./255,    \n",
    "    shear_range=0.1,    \n",
    "    zoom_range=0.1,    \n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    TrainingImagePath,    \n",
    "    target_size=(128,128),    \n",
    "    batch_size=32,    \n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(    \n",
    "    TestImagePath,    \n",
    "    target_size = (128,128),    \n",
    "    batch_size=32,    \n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory(    \n",
    "    ValidationImagePath,    \n",
    "    target_size=(128,128),    \n",
    "    batch_size=32,    \n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "def showImages(class_name): \n",
    "     random_index = random.choice(list(range(1,49)))  \n",
    "     folder_path = os.path.join(TrainingImagePath, class_name)  \n",
    "     try:    \n",
    "        image_path = os.path.join(folder_path,str(random_index).zfill(3)+\".jpg\")    \n",
    "        plt.imshow(mping.imread(image_path))  \n",
    "        except:    \n",
    "            image_path = os.path.join(folder_path,str(random_index).zfill(2)+\".jpg\")    \n",
    "            plt.imshow(mping.imread(image_path))  \n",
    "        plt.title(class_name)  \n",
    "        plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "for labels,number in training_set.class_indices.items():  \n",
    "    plt.subplot(6,6,number+1)  \n",
    "    showImages(labels)\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#################### Creating lookup table for all balls ##############################'''\n",
    "# class_indices have the numeric tag for each balls\n",
    "TrainClasses=training_set.class_indices\n",
    "\n",
    "# Storing the face and the numeric tag for future reference\n",
    "ResultMap={}for ballValue,ballName in zip(TrainClasses.values(),TrainClasses.keys()):    \n",
    "    ResultMap[ballValue]=ballName\n",
    "    \n",
    "# Saving the face map for future reference\n",
    "import pickle\n",
    "with open(R\"E:\\Data Sets\\Balls Classification\\ResultsMap.pkl\", 'wb') as f:    \n",
    "    pickle.dump(ResultMap, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "print(\"Mapping of Face and its ID\",ResultMap)\n",
    "\n",
    "# The number of neurons for the output layer is equal to the number of faces\n",
    "OutputNeurons=len(ResultMap)\n",
    "print('\\n The Number of output neurons: ', OutputNeurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier= Sequential()\n",
    "\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), strides=(1, 1), input_shape=(128,128,3), activation='relu'))\n",
    "\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "''\n",
    "classifier.add(Convolution2D(64, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(256, activation='relu'))\n",
    "classifier.add(Dense(OutputNeurons, activation='softmax'))\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer = 'rmsprop', metrics=[\"accuracy\"])\n",
    "classifier.summary()\n",
    "import time\n",
    "# Measuring the time taken by the model to train\n",
    "StartTime=time.time()\n",
    "\n",
    "# Starting the model training\n",
    "model_history=classifier.fit_generator(                                        \n",
    "    training_set,                                        \n",
    "    steps_per_epoch=len(training_set),                                        \n",
    "    epochs=20,                                        \n",
    "    validation_data=valid_set,                                        \n",
    "    validation_steps=len(valid_set),                                        \n",
    "    verbose=1)\n",
    "\n",
    "EndTime=time.time()\n",
    "print(\"############### Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes #############')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_history.history['accuracy']\n",
    "val_accuracy  = model_history.history['val_accuracy']\n",
    "\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(accuracy, label = \"Training accuracy\")\n",
    "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs validation accuracy\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(loss, label = \"Training loss\")\n",
    "plt.plot(val_loss, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs validation loss\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
